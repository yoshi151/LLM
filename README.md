<b>PDF Q&A using LangChain + Ollama (LLaMA 3)</b>
Features

Load and chunk a PDF file

Generate embeddings using all-MiniLM-L6-v2 or multilingual models

Store embeddings in a FAISS vector database

Ask questions using natural language, and get answers retrieved from the PDF

Uses Ollama to run LLaMA 3 model locally


<b>Fine-Tuning TinyLlama-1.1B with LoRA (Low-Rank Adaptation)</b>

Features

TinyLlama-1.1B (small, fast LLM)

LoRA fine-tuning (via peft)

4-bit quantization using BitsAndBytes (memory efficient)

Hugging Face datasets, transformers, and Trainer support

Token-level training with padded inputs

Saves the final fine-tuned model
