<b>Features for PDF Q&A using LangChain + Ollama (LLaMA 3)</b>

Load and chunk a PDF file

Generate embeddings using all-MiniLM-L6-v2 or multilingual models

Store embeddings in a FAISS vector database

Ask questions using natural language, and get answers retrieved from the PDF

Uses Ollama to run LLaMA 3 model locally
